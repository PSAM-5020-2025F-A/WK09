{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Flow for Training/Fitting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/PSAM-5020-2025F-A/5020-utils/raw/main/src/data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from data_utils import object_from_json_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Stages\n",
    "- Data Prep: Encoding, Scaling, Clustering, sometimes Splitting into train/test datasets\n",
    "- Modeling: `fit()` classifier\n",
    "- Evaluation: `predict()` and measure error\n",
    "\n",
    "#### Data Prep:\n",
    "Do we need to split our data, or is it already split into train/test sets?\n",
    "\n",
    "If it's already split we prepare the Encoding, Scaling, Clustering objects using the `train` data (usually with the `fit_transform()` function), and then we use those same objects to encode, scale, cluster the `test` data (usually with the `transform()` function).\n",
    "\n",
    "If the data is not split into two datasets, we could first split it and repeat the steps above, or, although it might add a bit of bias to the models, we could perform encoding, scaling, clustering with `fit_transform()` on the entire dataset and then only split the already encoded, scaled, clustered data. This biases the encoder, scaler, cluster models, and in turn, the model, but is a bit easier to perform.\n",
    "\n",
    "#### Modeling\n",
    "Once we have `train` and `test` datasets that has been encoded, scaled, clustered, we can use the `train` dataset to fit a supervised model (classifier, regression, etc).\n",
    "\n",
    "Here we will usually call a `fit()` function with the training dataset's features and, separately, its labels or outcome variable values. Something like `fit(features, labels)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "We have a model we trained/fitted with the `train` dataset. Now we can measure how well it actually performs once it's used without the correct labels.\n",
    "\n",
    "Here we usually call `predict()` with a dataset's features to get label or regression predictions.\n",
    "\n",
    "We want to call `predict()` for both the `train` and `test` dataset, and then measure how close those predictions are to the actual labels and values that we have in our dataset.\n",
    "\n",
    "Eavluating with the `train` dataset will tell us if the model is capable of learning anything about the data. Evaluating with the `train` dataset will tell us if the model is capable of learning patterns and trends beyond the data that is fed to it.\n",
    "\n",
    "It's common for the model to perform better with the `train` data since it was trained using that data and labels, but the `test` dataset error is what's more important because it will tell us what kind of error to expect from data that the model hasn't seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Classifying penguins based on measurements.\n",
    "\n",
    "Let's load a dataset and look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PENGUIN_URL = \"https://raw.githubusercontent.com/PSAM-5020-2025F-A/5020-utils/refs/heads/main/datasets/json/penguins.json\"\n",
    "penguin_data = object_from_json_url(PENGUIN_URL)\n",
    "\n",
    "display(penguin_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't have separate train and test data, so we will have to split our dataset before doing any encoding/scaling/pre-processing. \n",
    "\n",
    "<img src=\"./imgs/datasplit-00.jpg\" width=\"720px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put in DataFrames\n",
    "# TODO: Encode Species Label (we can do encoding before we split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "\n",
    "Using `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with train_test_split()\n",
    "penguin_train, penguin_test = train_test_split(penguin_df, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: scale training data\n",
    "# Keep sex and label encoded as int values for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: scale test data\n",
    "# Keep sex and label encoded as int values for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model/Fit\n",
    "\n",
    "We can train our model now. We're going to use a `RandomForestClassifier` and `fit()` it with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: separate features and outcomes (outcome can be sex, species or both)\n",
    "\n",
    "# TODO: fit RandomForestClassifier for sex classification\n",
    "\n",
    "# TODO: fit RandomForestClassifier for species classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "We can now run predictions for both `train` and `test` data and measure error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: predict() for train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure classification error with classification_error()\n",
    "display(classification_error(train_scaled_df[\"sex\"], train_sex_pred))\n",
    "display(classification_error(test_scaled_df[\"sex\"], test_sex_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Confusion (Matrix)\n",
    "\n",
    "`display_confusion_matrix(labels, predictions, display_labels=unique_labels)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrices\n",
    "display_confusion_matrix(train_scaled_df[\"sex\"], train_sex_pred, display_labels=penguin_df[\"sex\"].unique().tolist())\n",
    "display_confusion_matrix(test_scaled_df[\"sex\"], test_sex_pred, display_labels=penguin_df[\"sex\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both Sex and Species ?\n",
    "\n",
    "We can fit a `RandomForestClassifier` to predict multiple classes at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# something like this\n",
    "penguin_model = RandomForestClassifier().fit(train_features, train_scaled_df[[\"label\", \"sex\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run predict() on train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the results\n",
    "\n",
    "We could've re-organized our dataset to have one output variable that combined `sex` and `label`, since there are $6$ possible combinations of those two features. If we did that, we would be able to plot a single confusion matrix to show the results of our multi-class, multi-output classifier.\n",
    "\n",
    "Since we didn't combine the outcome variables, we'll have to plot these separately. The classifier model was the same and it is able to classify our penguins into $6$ classes, but we have to look at the confusion matrixes for each output variable separately.\n",
    "\n",
    "<h3 style=\"color:#f00;\">Warning</h3>\n",
    "\n",
    "Unlike the scalars, the `predict()` functions in `sklearn` lose their column names. We have to remember which column represents which outcome variable, or create a new `DataFrame` with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_df = pd.DataFrame(train_pred, columns=[\"label\", \"sex\"])\n",
    "test_pred_df = pd.DataFrame(test_pred, columns=[\"label\", \"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrices\n",
    "display_confusion_matrix(train_scaled_df[\"sex\"], train_pred_df[\"sex\"], display_labels=penguin_df[\"sex\"].unique().tolist())\n",
    "display_confusion_matrix(test_scaled_df[\"sex\"], test_pred_df[\"sex\"], display_labels=penguin_df[\"sex\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at confusion matrices\n",
    "display_confusion_matrix(train_scaled_df[\"label\"], train_pred_df[\"label\"], display_labels=penguin_df[\"species\"].unique().tolist())\n",
    "display_confusion_matrix(test_scaled_df[\"label\"], test_pred_df[\"label\"], display_labels=penguin_df[\"species\"].unique().tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5020",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
